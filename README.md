# âš–ï¸ NyayaSetu AI 

> Voice-First Legal AI for Consumer Rights in India

NyayaSetu AI is a production-grade AI system that democratizes access to consumer rights information in India through source-grounded, explainable AI guidance.

---

## ğŸ¯ Project Overview

NyayaSetu AI helps Indian citizens:

- Understand consumer rights under the Consumer Protection Act, 2019
- Navigate complex legal language through simple explanations
- Draft structured complaints for grievance filing
- Identify the appropriate grievance redressal mechanism
- Access legal information through voice-first, multilingual interfaces

---

## ğŸ— System Architecture

```
User (Voice/Text)
      â†“
Frontend PWA (React)
      â†“
AI Orchestrator
      â†“
RAG Engine + Grievance Router + Complaint Drafter
      â†“
Legal Knowledge Base (Vector DB)
      â†“
Response + Citations + Confidence Score
```

---

## ğŸ§  RAG Knowledge Base Implementation

The system uses a Retrieval-Augmented Generation (RAG) pipeline built on the Consumer Protection Act, 2019.

### Knowledge Base Processing Pipeline

**1. PDF Text Extraction**
- Extracts text from the Consumer Protection Act, 2019 PDF
- Preserves document hierarchy (chapters, sections, clauses)
- Maintains legal structure and numbering

**2. Text Cleaning & Structuring**
- Removes page numbers, headers, footers, and formatting artifacts
- Preserves legal numbering, definitions, and section structure
- Identifies 99 sections across 10 chapters

**3. Intelligent Chunking**
- **Strategy**: Section-wise logical grouping with sentence boundary detection
- **Chunk Size**: 700-1000 tokens (average: 850 tokens)
- **Overlap**: 100-150 tokens between chunks for context continuity
- **Total Chunks**: 111 chunks created from the Act

**4. Metadata Tagging**

Each chunk includes structured metadata:
```json
{
  "act": "Consumer Protection Act, 2019",
  "chapter": "Chapter II: Consumer Protection Councils",
  "section": "Section 7",
  "title": "Objects of State Council",
  "language": "English"
}
```

**5. Vector Embeddings**
- **Model**: sentence-transformers/all-MiniLM-L6-v2
- **Dimension**: 384-dimensional vectors
- **Purpose**: Semantic search and retrieval
- **Compatibility**: Pinecone, Weaviate, Elasticsearch, FAISS

**6. Storage Formats**
- `knowledge_base.json`: Full knowledge base with embeddings
- `metadata_index.json`: Metadata index for quick reference
- `pinecone_ready.json`: Vector database ingestion format
- `stats.json`: Summary statistics

### Knowledge Base Statistics

```
Total Chunks:        111
Total Sections:      99
Total Chapters:      10
Avg Chunk Size:      1,172 characters (~293 tokens)
Embedding Dimension: 384
```

---

## ğŸ“ Project Structure

```
NyayaSetu-AI/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â””â”€â”€ rag/
â”‚       â”œâ”€â”€ rag_kb_setup.py      # Knowledge base builder
â”‚       â””â”€â”€ test_rag_query.py    # Query testing script
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ CPA2019.pdf          # Consumer Protection Act, 2019
â”œâ”€â”€ knowledge_base/
â”‚   â”œâ”€â”€ knowledge_base.json      # Full KB with embeddings
â”‚   â”œâ”€â”€ metadata_index.json      # Metadata index
â”‚   â”œâ”€â”€ pinecone_ready.json      # Vector DB format
â”‚   â””â”€â”€ stats.json               # Statistics
â”œâ”€â”€ docs/
â””â”€â”€ .kiro/
    â””â”€â”€ specs/
        â””â”€â”€ nyayasetu-ai-navigator/
            â”œâ”€â”€ requirements.md   # System requirements
            â””â”€â”€ design.md         # Technical design
```

---

## ğŸš€ Getting Started

### Prerequisites

```bash
pip install -r requirements.txt
```

### Build Knowledge Base

Run the RAG setup script to process the Consumer Protection Act PDF:

```bash
python src/rag/rag_kb_setup.py
```

This will:
1. Extract text from `data/raw/CPA2019.pdf`
2. Clean and structure the content
3. Create 111 chunks with metadata
4. Generate 384-dimensional embeddings
5. Save to `knowledge_base/` directory

### Test Semantic Retrieval

Test the knowledge base with sample queries:

```bash
python src/rag/test_rag_query.py
```

Sample queries:
- "What are consumer rights?"
- "How to file a complaint?"
- "What is the definition of consumer?"
- "What are unfair trade practices?"
- "Who can file a consumer complaint?"

---

## ğŸ” Design Principles

**Safety-First AI Governance:**
- Source-grounded responses (every claim cites legal text)
- Multi-layer hallucination prevention
- Confidence scoring (low confidence â†’ human escalation)
- Citation accuracy target: â‰¥95%

**Regulatory Compliance:**
- DPDP Act 2023 compliance (data minimization, consent management)
- IT Act 2000 alignment (encryption, audit logging)
- WCAG 2.1 AA accessibility standards
- Data residency: All data stored in India

**Inclusion-First Architecture:**
- Voice-first interaction for low-literacy users
- Multilingual support (English, Hindi, regional languages)
- Low-bandwidth optimization (works on 2G networks)
- Offline capability via Progressive Web App

**Production Readiness:**
- Configuration-driven jurisdiction thresholds
- Comprehensive AI observability and monitoring
- Progressive degradation (maintains core functionality during failures)
- Multi-region deployment with <4 hour RTO

---

## ğŸ¯ Key Technical Innovations

1. **Configurable Jurisdiction Engine**: Legal thresholds updatable without code redeployment
2. **Source-Grounded RAG**: Multi-layer hallucination prevention with citation enforcement
3. **AI Observability**: Real-time monitoring of citation accuracy, hallucination rate, routing accuracy
4. **Progressive Degradation**: Maintains functionality during partial failures
5. **DPDP Compliance by Design**: Data protection built into architecture from day one
6. **Accessibility-First**: WCAG 2.1 AA compliance verified through automated and manual testing

---

## ğŸ“Š Performance Metrics

- **Citation Accuracy**: â‰¥95% target
- **Hallucination Rate**: â‰¤2% target
- **Retrieval Relevance**: Top-3 relevant â‰¥90%
- **Response Latency**: â‰¤3 seconds (95th percentile)
- **System Uptime**: 99% target

---

## ğŸ›  Technology Stack

**AI & ML:**
- Sentence Transformers (embeddings)
- OpenAI GPT-4 / Anthropic Claude (LLM)
- Vector Database (Pinecone/Weaviate)

**Backend:**
- Python 3.12+
- FastAPI (API layer)
- PostgreSQL (user data, config)
- Redis (caching, session management)

**Frontend:**
- React + TypeScript
- Progressive Web App (PWA)
- Web Speech API (voice interface)

**Infrastructure:**
- AWS (Mumbai region)
- ECS Fargate (containers)
- CloudFront (CDN)
- CloudWatch (monitoring)

---

## ğŸ“š Documentation

- **Requirements**: `.kiro/specs/nyayasetu-ai-navigator/requirements.md`
- **Technical Design**: `.kiro/specs/nyayasetu-ai-navigator/design.md`
- **Knowledge Base Stats**: `knowledge_base/stats.json`

---

## ğŸš€ Roadmap

**Completed:**
- âœ… System architecture and design
- âœ… RAG knowledge base implementation
- âœ… Vector embeddings generation
- âœ… Semantic search capability

**In Progress:**
- â³ Vector database integration (Pinecone)
- â³ RAG pipeline with LLM integration
- â³ Confidence scoring and hallucination prevention
- â³ API development

**Planned:**
- ğŸ“‹ Complaint drafting module
- ğŸ“‹ Grievance routing engine
- ğŸ“‹ Voice interface integration
- ğŸ“‹ Multi-language support
- ğŸ“‹ Frontend PWA development
- ğŸ“‹ AWS deployment

---

## âš  Disclaimer

NyayaSetu AI provides informational guidance based on the Consumer Protection Act, 2019. It does not provide legal advice, representation, or guarantee outcomes. Users should consult qualified legal professionals for complex cases.

---

## ğŸ“„ License

See [LICENSE](LICENSE) file for details.

---

**Built for AI For Bharat Hackathon 2026**
